
# ğŸ§ ğŸ“š Alice LLM Lab  
*A Tiny Transformer Language Model with Retrieval-Augmented Generation*

![Python](https://img.shields.io/badge/Python-3.x-blue)
![Framework](https://img.shields.io/badge/UI-Streamlit-red)
![Model](https://img.shields.io/badge/Model-Custom%20Transformer-green)
![Status](https://img.shields.io/badge/Status-Learning%20Project-yellow)

---

## ğŸ“Œ Project Overview

Alice LLM Lab is a **small transformer based language model** trained on *Aliceâ€™s Adventures in Wonderland*.  
This project was built as a **hands-on learning exercise** to understand how language models work end to end, starting from raw text, moving through training a custom transformer, and finally experimenting with retrieval based context and interactive inference.

Everything runs locally and the focus is on **clarity, experimentation, and understanding**, rather than production scale performance.

---

## ğŸ¯ What this project does

This project allows you to:

ğŸ“– Train a tiny **character-level transformer** from scratch  
âœï¸ Generate text in the style of the training data  
ğŸ§© Experiment with **retrieval-augmented generation** using a local SQLite database  
ğŸ–¥ï¸ Interact with the model through a **Streamlit-based interface**  

The goal is not to build a large model, but to clearly understand **each moving part** of a modern LLM-style pipeline.

---

## ğŸ§  How it works (high level)

Think of the system as a simple pipeline:

1ï¸âƒ£ Load and clean the raw *Alice in Wonderland* text  
2ï¸âƒ£ Split the text into smaller chunks for training and retrieval  
3ï¸âƒ£ Train a character-level transformer on the processed text  
4ï¸âƒ£ Store text chunks in a SQLite database  
5ï¸âƒ£ Retrieve the most relevant chunks for a given prompt  
6ï¸âƒ£ Use the retrieved context to guide text generation  

When retrieval is enabled, the generated output stays **grounded in the original text**.

---

## ğŸ—‚ï¸ Project Structure (explained)

```
alice-mini-llm/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Streamlit UI for generation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ alice.txt           # Original raw text
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ alice_clean.txt     # Cleaned text
â”‚   â”‚   â”œâ”€â”€ chunks.jsonl        # Chunked text for retrieval
â”‚   â”‚   â”œâ”€â”€ train.txt           # Training split
â”‚   â”‚   â””â”€â”€ val.txt             # Validation split
â”‚   â””â”€â”€ texts.db                # SQLite database for RAG
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/            # Model checkpoints
â”‚   â””â”€â”€ plots/
â”‚       â””â”€â”€ loss.png            # Training loss curve
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep/              # Dataset preparation
â”‚   â”œâ”€â”€ model/                  # Transformer, training, generation
â”‚   â”œâ”€â”€ rag/                    # Retrieval logic
â”‚   â”œâ”€â”€ eval/                   # Evaluation helpers
â”‚   â”œâ”€â”€ config.py               # Central configuration
â”‚   â””â”€â”€ inference.py            # Shared inference helpers
â”‚
â”œâ”€â”€ Execution_Guide.md
â”œâ”€â”€ Project_Report.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
```

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Create a virtual environment (recommended)

```
python -m venv .venv
```

Activate it:

**Windows (PowerShell)**

```
.venv\Scripts\Activate.ps1
```

**macOS / Linux**

```
source .venv/bin/activate
```

---

### 2ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

---

## ğŸ§ª Dataset Preparation

Run the dataset builder to clean the raw text, create chunks, and prepare training files.

```
python src/data_prep/dataset_builder.py
```

This step also creates the SQLite database used for retrieval.

---

## ğŸ‹ï¸ Model Training

```
python src/model/train.py
```

Training outputs include:

ğŸ“¦ Model checkpoints  
ğŸ“‰ Training loss curve saved under `outputs/plots/`

---

## âœ¨ Text Generation

**Standard generation**

```
python src/model/generate.py --prompt "Alice was beginning to"
```

**Retrieval-augmented generation**

```
python src/rag/rag_generate.py --prompt "Who is the Queen of Hearts?" --top_k 3
```

Retrieval uses **TF-IDF similarity** over stored text chunks.

---

## ğŸ–¥ï¸ Streamlit App

Run the interactive UI:

```
streamlit run app/streamlit_app.py
```

The app lets you:

ğŸ“ Enter prompts  
ğŸ›ï¸ Adjust generation parameters  
ğŸ“š Enable or disable retrieval  

---

## âš ï¸ Notes & Limitations

âœ”ï¸ This is a **learning-focused prototype**  
âœ”ï¸ The model is intentionally small  
âœ”ï¸ Retrieval quality depends on chunking and similarity scoring  
âœ”ï¸ Performance depends on local hardware  

---

## ğŸ™Œ Author

**Abinash Prasana Selvanathan**  

â­ If you found this project useful, feel free to star the repository.
